{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passengers predicted to survive:\n",
      "+----+-----+------+-------+-------+----------+----------+-------+-----+-------+----------+--------------------+\n",
      "|    | sex | age  | sibsp | parch |   fare   | embarked | class | who | alone | survived | predicted_survived |\n",
      "+----+-----+------+-------+-------+----------+----------+-------+-----+-------+----------+--------------------+\n",
      "| 1  | 0.0 | 38.0 |  1.0  |  0.0  | 71.2833  |   0.0    |  0.0  | 2.0 |  0.0  |   1.0    |        1.0         |\n",
      "| 2  | 0.0 | 26.0 |  0.0  |  0.0  |  7.925   |   2.0    |  2.0  | 2.0 |  1.0  |   1.0    |        1.0         |\n",
      "| 3  | 0.0 | 35.0 |  1.0  |  0.0  |   53.1   |   2.0    |  0.0  | 2.0 |  0.0  |   1.0    |        1.0         |\n",
      "| 8  | 0.0 | 27.0 |  0.0  |  2.0  | 11.1333  |   2.0    |  2.0  | 2.0 |  0.0  |   1.0    |        1.0         |\n",
      "| 9  | 0.0 | 14.0 |  1.0  |  0.0  | 30.0708  |   0.0    |  1.0  | 0.0 |  0.0  |   1.0    |        1.0         |\n",
      "| 10 | 0.0 | 4.0  |  1.0  |  1.0  |   16.7   |   2.0    |  2.0  | 0.0 |  0.0  |   1.0    |        1.0         |\n",
      "| 11 | 0.0 | 58.0 |  0.0  |  0.0  |  26.55   |   2.0    |  0.0  | 2.0 |  1.0  |   1.0    |        1.0         |\n",
      "| 15 | 0.0 | 55.0 |  0.0  |  0.0  |   16.0   |   2.0    |  1.0  | 2.0 |  1.0  |   1.0    |        1.0         |\n",
      "| 17 | 1.0 | 28.0 |  0.0  |  0.0  |   13.0   |   2.0    |  1.0  | 1.0 |  1.0  |   1.0    |        1.0         |\n",
      "| 19 | 0.0 | 28.0 |  0.0  |  0.0  |  7.225   |   0.0    |  2.0  | 2.0 |  1.0  |   1.0    |        1.0         |\n",
      "| 22 | 0.0 | 15.0 |  0.0  |  0.0  |  8.0292  |   1.0    |  2.0  | 0.0 |  1.0  |   1.0    |        1.0         |\n",
      "| 23 | 1.0 | 28.0 |  0.0  |  0.0  |   35.5   |   2.0    |  0.0  | 1.0 |  1.0  |   1.0    |        1.0         |\n",
      "| 28 | 0.0 | 28.0 |  0.0  |  0.0  |  7.8792  |   1.0    |  2.0  | 2.0 |  1.0  |   1.0    |        1.0         |\n",
      "| 31 | 0.0 | 28.0 |  1.0  |  0.0  | 146.5208 |   0.0    |  0.0  | 2.0 |  0.0  |   1.0    |        1.0         |\n",
      "| 32 | 0.0 | 28.0 |  0.0  |  0.0  |   7.75   |   1.0    |  2.0  | 2.0 |  1.0  |   1.0    |        1.0         |\n",
      "| 33 | 1.0 | 66.0 |  0.0  |  0.0  |   10.5   |   2.0    |  1.0  | 1.0 |  1.0  |   0.0    |        1.0         |\n",
      "| 43 | 0.0 | 3.0  |  1.0  |  2.0  | 41.5792  |   0.0    |  1.0  | 0.0 |  0.0  |   1.0    |        1.0         |\n",
      "| 47 | 0.0 | 28.0 |  0.0  |  0.0  |   7.75   |   1.0    |  2.0  | 2.0 |  1.0  |   1.0    |        1.0         |\n",
      "| 52 | 0.0 | 49.0 |  1.0  |  0.0  | 76.7292  |   0.0    |  0.0  | 2.0 |  0.0  |   1.0    |        1.0         |\n",
      "| 53 | 0.0 | 29.0 |  1.0  |  0.0  |   26.0   |   2.0    |  1.0  | 2.0 |  0.0  |   1.0    |        1.0         |\n",
      "+----+-----+------+-------+-------+----------+----------+-------+-----+-------+----------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "file_path = 'Titanic.csv'  \n",
    "titanic_data = pd.read_csv('Titanic.csv')\n",
    "\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "titanic_data['age'] = imputer.fit_transform(titanic_data[['age']])\n",
    "\n",
    "\n",
    "# Convert categorical variables to numerical\n",
    "label_encoders = {}\n",
    "for column in ['sex', 'embarked', 'class', 'who', 'alone']:\n",
    "    label_encoders[column] = LabelEncoder()\n",
    "    titanic_data[column] = label_encoders[column].fit_transform(titanic_data[column])\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = titanic_data.drop('survived', axis=1)\n",
    "y = titanic_data['survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Predict survival for all passengers\n",
    "titanic_data['predicted_survived'] = rf_model.predict(X)\n",
    "\n",
    "# Filter passengers that are predicted to survive\n",
    "survived_passengers = titanic_data[titanic_data['predicted_survived'] == 1]\n",
    "\n",
    "# Display the passengers predicted to survive\n",
    "print('Passengers predicted to survive:')\n",
    "print(tabulate(survived_passengers.head(20), headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0    0\n",
      "label         0\n",
      "text          0\n",
      "label_num     0\n",
      "dtype: int64\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       1.00      0.99      0.99       742\n",
      "        spam       0.97      0.99      0.98       293\n",
      "\n",
      "    accuracy                           0.99      1035\n",
      "   macro avg       0.98      0.99      0.99      1035\n",
      "weighted avg       0.99      0.99      0.99      1035\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the dataset\n",
    "dataset_path = 'spam_ham_dataset.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "emails_df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Check for missing values\n",
    "print(emails_df.isnull().sum())\n",
    "\n",
    "# Extract the text of the emails\n",
    "email_texts = emails_df['text']\n",
    "\n",
    "# Extract the labels\n",
    "email_labels = emails_df['label']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vect = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "# Fit and transform the email texts\n",
    "email_tfidf = tfidf_vect.fit_transform(email_texts)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(email_tfidf, email_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "log_reg_model = LogisticRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = log_reg_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label='spam')\n",
    "recall = recall_score(y_test, y_pred, pos_label='spam')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print('Classification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
